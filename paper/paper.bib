
@article{chen2015ucr,
  title={The ucr time series classification archive},
  author={Chen, Yanping and Keogh, Eamonn and Hu, Bing and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo},
  year={2015},
  publisher={July}
}

@article{Bagnall2017,
author="Bagnall, Anthony
and Lines, Jason
and Bostrom, Aaron
and Large, James
and Keogh, Eamonn",
title="The great time series classification bake off: a review and experimental evaluation of recent algorithmic advances",
journal="Data Mining and Knowledge Discovery",
year="2017",
month="May",
day="01",
volume="31",
number="3",
pages="606--660",
abstract="In the last 5Â years there have been a large number of new time series classification algorithms proposed in the literature. These algorithms have been evaluated on subsets of the 47 data sets in the University of California, Riverside time series classification archive. The archive has recently been expanded to 85 data sets, over half of which have been donated by researchers at the University of East Anglia. Aspects of previous evaluations have made comparisons between algorithms difficult. For example, several different programming languages have been used, experiments involved a single train/test split and some used normalised data whilst others did not. The relaunch of the archive provides a timely opportunity to thoroughly evaluate algorithms on a larger number of datasets. We have implemented 18 recently proposed algorithms in a common Java framework and compared them against two standard benchmark classifiers (and each other) by performing 100 resampling experiments on each of the 85 datasets. We use these results to test several hypotheses relating to whether the algorithms are significantly more accurate than the benchmarks and each other. Our results indicate that only nine of these algorithms are significantly more accurate than both benchmarks and that one classifier, the collective of transformation ensembles, is significantly more accurate than all of the others. All of our experiments and results are reproducible: we release all of our code, results and experimental details and we hope these experiments form the basis for more robust testing of new algorithms in the future.",
issn="1573-756X",
doi="10.1007/s10618-016-0483-9",
url="https://doi.org/10.1007/s10618-016-0483-9"
}


@article{hallweka,
 author = {Hall, Mark and Frank, Eibe and Holmes, Geoffrey and Pfahringer, Bernhard and Reutemann, Peter and Witten, Ian H.},
 title = {The WEKA Data Mining Software: An Update},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {June 2009},
 volume = {11},
 number = {1},
 month = nov,
 year = {2009},
 issn = {1931-0145},
 pages = {10--18},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1656274.1656278},
 doi = {10.1145/1656274.1656278},
 acmid = {1656278},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@misc{urbanek2013rjava,
  title={rJava: Low-level R to Java interface},
  author={Urbanek, Simon},
  year={2013},
  publisher={R package version 0.9-6, URL http://CRAN. R-project. org/package= rJava}
}

@article{team2013r,
  title={R: A language and environment for statistical computing},
  author={Team, R Core and others},
  year={2013},
  publisher={Vienna, Austria}
}

@inproceedings{geurts2001pattern,
  title={Pattern extraction for time series classification},
  author={Geurts, Pierre},
  booktitle={European Conference on Principles of Data Mining and Knowledge Discovery},
  pages={115--127},
  year={2001},
  organization={Springer}
}

@INPROCEEDINGS{HIVE-COTE,
author={J. {Lines} and S. {Taylor} and A. {Bagnall}},
booktitle={2016 IEEE 16th International Conference on Data Mining (ICDM)},
title={HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based Ensembles for Time Series Classification},
year={2016},
volume={},
number={},
pages={1041-1046},
keywords={neural nets;pattern classification;time series;HIVE-COTE;hierarchical vote collective of transformation-based ensembles;time series classification;TSC algorithms;data representations;CNN structure;modular hierarchical structure;probabilistic voting;interval-based classifier;dictionary classifier;frequency domain classifier;convolutional neural networks;Time series analysis;Machine learning;Machine learning algorithms;Training;Classification algorithms;Prediction algorithms;Dictionaries;time series classification;time series;ensemble classifiers;deep learning},
doi={10.1109/ICDM.2016.0133},
ISSN={2374-8486},
month={Dec},}

@INPROCEEDINGS{7837946,
author={J. {Lines} and S. {Taylor} and A. {Bagnall}},
booktitle={2016 IEEE 16th International Conference on Data Mining (ICDM)},
title={HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based Ensembles for Time Series Classification},
year={2016},
volume={},
number={},
pages={1041-1046},
keywords={neural nets;pattern classification;time series;HIVE-COTE;hierarchical vote collective of transformation-based ensembles;time series classification;TSC algorithms;data representations;CNN structure;modular hierarchical structure;probabilistic voting;interval-based classifier;dictionary classifier;frequency domain classifier;convolutional neural networks;Time series analysis;Machine learning;Machine learning algorithms;Training;Classification algorithms;Prediction algorithms;Dictionaries;time series classification;time series;ensemble classifiers;deep learning},
doi={10.1109/ICDM.2016.0133},
ISSN={2374-8486},
month={Dec},}



